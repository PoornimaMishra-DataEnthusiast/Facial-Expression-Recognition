{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\n\n# Importing Deep Learning Libraries\n\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop","metadata":{"execution":{"iopub.status.busy":"2022-02-23T07:39:12.915869Z","iopub.execute_input":"2022-02-23T07:39:12.916727Z","iopub.status.idle":"2022-02-23T07:39:12.924633Z","shell.execute_reply.started":"2022-02-23T07:39:12.916666Z","shell.execute_reply":"2022-02-23T07:39:12.923477Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"**Displaying Images**","metadata":{}},{"cell_type":"code","source":"picture_size = 48\nfolder_path = \"../input/face-expression-recognition-dataset/images/\"","metadata":{"execution":{"iopub.status.busy":"2022-02-23T07:39:36.588021Z","iopub.execute_input":"2022-02-23T07:39:36.588670Z","iopub.status.idle":"2022-02-23T07:39:36.593112Z","shell.execute_reply.started":"2022-02-23T07:39:36.588628Z","shell.execute_reply":"2022-02-23T07:39:36.592173Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"expression = 'happy'\n\nplt.style.use(\"dark_background\")\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n    plt.imshow(img)   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T07:39:42.045442Z","iopub.execute_input":"2022-02-23T07:39:42.045689Z","iopub.status.idle":"2022-02-23T07:39:42.884355Z","shell.execute_reply.started":"2022-02-23T07:39:42.045662Z","shell.execute_reply":"2022-02-23T07:39:42.883243Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"**Making Training and Validation Data**","metadata":{}},{"cell_type":"code","source":"batch_size  = 128\n\ndatagen_train  = ImageDataGenerator()\ndatagen_val = ImageDataGenerator()\n\ntrain_set = datagen_train.flow_from_directory(folder_path+\"train\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)\n\n\ntest_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T07:39:58.284339Z","iopub.execute_input":"2022-02-23T07:39:58.284634Z","iopub.status.idle":"2022-02-23T07:40:04.017730Z","shell.execute_reply.started":"2022-02-23T07:39:58.284604Z","shell.execute_reply":"2022-02-23T07:40:04.016880Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**Model Building**","metadata":{}},{"cell_type":"code","source":"no_of_classes=7\n\nmodel=Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding=\"same\",input_shape=(48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes,activation=\"softmax\"))\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T07:41:37.546322Z","iopub.execute_input":"2022-02-23T07:41:37.546853Z","iopub.status.idle":"2022-02-23T07:41:38.000138Z","shell.execute_reply.started":"2022-02-23T07:41:37.546814Z","shell.execute_reply":"2022-02-23T07:41:37.999335Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**Fitting the Model with Training and Validation Data**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n\nepochs = 48\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-23T07:46:05.706572Z","iopub.execute_input":"2022-02-23T07:46:05.707544Z","iopub.status.idle":"2022-02-23T07:46:05.724649Z","shell.execute_reply.started":"2022-02-23T07:46:05.707494Z","shell.execute_reply":"2022-02-23T07:46:05.723542Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_set,\n                                steps_per_epoch=train_set.n//train_set.batch_size,\n                                epochs=epochs,\n                                validation_data = test_set,\n                                validation_steps = test_set.n//test_set.batch_size,\n                                callbacks=callbacks_list\n                                )","metadata":{"execution":{"iopub.status.busy":"2022-02-23T07:46:12.706598Z","iopub.execute_input":"2022-02-23T07:46:12.707450Z","iopub.status.idle":"2022-02-23T09:18:39.201770Z","shell.execute_reply.started":"2022-02-23T07:46:12.707393Z","shell.execute_reply":"2022-02-23T09:18:39.200844Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model.save_weights('face_emotion_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-23T09:18:39.375562Z","iopub.execute_input":"2022-02-23T09:18:39.375834Z","iopub.status.idle":"2022-02-23T09:18:39.459274Z","shell.execute_reply.started":"2022-02-23T09:18:39.375802Z","shell.execute_reply":"2022-02-23T09:18:39.458251Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"**Plotting Accuracy & Loss**","metadata":{}},{"cell_type":"code","source":"plt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T09:19:27.210030Z","iopub.execute_input":"2022-02-23T09:19:27.210504Z","iopub.status.idle":"2022-02-23T09:19:27.573917Z","shell.execute_reply.started":"2022-02-23T09:19:27.210458Z","shell.execute_reply":"2022-02-23T09:19:27.572701Z"},"trusted":true},"execution_count":49,"outputs":[]}]}